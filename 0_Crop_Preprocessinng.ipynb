{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import dask.array as da\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as geoms\n",
    "from shapely.geometry import box\n",
    "\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.merge import merge  \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from os import path \n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "import logging, sys\n",
    "import concurrent.futures\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient\n",
    "from azure.storage.blob import ContentSettings, ContainerClient\n",
    "from azure.storage.blob import ContainerClient\n",
    "import tqdm\n",
    "import rasterstats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year              = 2021\n",
    "tiles             = ['30SWG', '30SWH','30SXG', '30SXH', '30SXJ', '30SYH'] \n",
    "months            = ['01' ,'02','03','04','05','06','07','08','09','10','11', '12']\n",
    "days              = ['01' ,'02','03','04','05','06','07', '08', '09','10','11','12', '13','14','15','16','17','18','19','20','21','22','23','24','25','26', '27','28','29','30','31' ]\n",
    "\n",
    "#\n",
    "CONNECTION_STRING = \"DefaultEndpointsProtocol=https;AccountName=ccubed;AccountKey=b284EE1qXogSUEhsCmb3Z9m2YrcCGW3m+PsRdMlhguCOVLRoJKA+s6vQL61kMv/5mpUH5MFUsJczH8Dgo5jxhA==;EndpointSuffix=core.windows.net\"\n",
    "name              = \"_REFL.tif\"\n",
    "\n",
    "directory         = f\"../Data/Crop_Classification/S2/{year}/\"\n",
    "indices           = ['NDVI', 'SAVI', 'NDMI'] \n",
    "\n",
    "parcels           = '../Data/Crop_Classification/Crop_parcel_2021/Cultivos_regados_AH2021_v6.shp'\n",
    "\n",
    "Q3                = ['07','08', '09']\n",
    "indices_Q3        = ['NDVI', 'SAVI']\n",
    "percetiles        = [10, 20, 50 , 90 , 95 ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG 663\n",
      "30SWH 674\n",
      "30SXG 594\n",
      "30SXH 614\n",
      "30SXJ 619\n",
      "30SYH 624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Number of files\n",
    "for tile in tiles:\n",
    "        trg_path = Path(directory).joinpath(tile)\n",
    "        files = glob(f'{trg_path}/*/*.tif')\n",
    "        print(tile, len(files))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/30SWG\n",
      "../Data/Crop_Classification/S2/2021/30SWH\n",
      "../Data/Crop_Classification/S2/2021/30SXG\n",
      "../Data/Crop_Classification/S2/2021/30SXH\n",
      "../Data/Crop_Classification/S2/2021/30SXJ\n",
      "../Data/Crop_Classification/S2/2021/30SYH\n"
     ]
    }
   ],
   "source": [
    "for tile in tiles:\n",
    "    for month in months:\n",
    "        trg_path = Path(directory).joinpath(tile)\n",
    "        if not trg_path.joinpath(month).is_dir(): \n",
    "            trg_path.joinpath(month).mkdir(parents=True) \n",
    "    print(trg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk download of S2 Scenes from Azure Storage (ca.1h - ca. 1year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: S2B_MSIL2A_20210619T104619_N9999_R051_T30SWG_20220707T081456_REFL.tif\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def down_name(tile):\n",
    "        for month in months:\n",
    "            for day in days:\n",
    "                container = ContainerClient.from_connection_string(conn_str=CONNECTION_STRING, container_name=\"ccc-storage\")\n",
    "                prefix = f\"Sentinel-2/L2B/T{tile}/{year}/{month}/{day}/\"\n",
    "                blob_list = list(container.list_blobs(name_starts_with=prefix))\n",
    "                for blob in tqdm.tqdm(blob_list, disable=None, leave=False):\n",
    "                    if name in blob.name:\n",
    "                        file = blob.name.split('/')[6] \n",
    "                        download_file_path = os.path.join(directory,tile,month,file)\n",
    "                        if not path.isfile(download_file_path): \n",
    "                            print(\"Downloading:\", file)\n",
    "                            with open(download_file_path, \"wb\") as download_file:\n",
    "                                download_file.write(container.download_blob(blob,max_concurrency = 50).readall())\n",
    "                        #else:\n",
    "                            #print(\"Exist:\",file)\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(2)) as pool:\n",
    "        return pool.map(down_name, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation NDVI, SAVI, NDMI per each scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NDVI (Sentinel 2) = (B8 – B4) / (B8 + B4)\n",
    "- SAVI (Sentinel 2) = (B08 – B04) / (B08 + B04 + 0.428) * (1.428)\n",
    "- NDMI (Sentinel 2) = (B8 – B11) / (B8 + B11)\n",
    "\n",
    "\n",
    "File_REFL {B2,B3,B4,B5,B6,B7,B8A,B11,B12\n",
    "\n",
    "\n",
    "//https://github.com/DHI-GRAS/sen-et-input-scripts/blob/master/senet_input_creator/sentinel2_inputs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def calc_indices(tile):\n",
    "    for month in months:\n",
    "        files = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/*REFL.tif')\n",
    "        for file in files:   \n",
    "           \n",
    "            output_ndvi = ('{}_NDVI.tif'.format(file.split('\\\\')[-1][:-9]))\n",
    "            output_savi = ('{}_SAVI.tif'.format(file.split('\\\\')[-1][:-9]))\n",
    "            output_ndmi = ('{}_NDMI.tif'.format(file.split('\\\\')[-1][:-9]))\n",
    "            \n",
    "            if not path.isfile(output_ndmi):\n",
    "                with rasterio.open(file) as src:\n",
    "                    \n",
    "                     band_red = src.read(3)\n",
    "                     band_nir = src.read(7)\n",
    "                     band_swir = src.read(8)\n",
    "                        \n",
    "                     ndvi = (band_nir.astype(float) - band_red.astype(float)) / (band_nir.astype(float) + band_red.astype(float))\n",
    "                     savi = (band_nir.astype(float) - band_red.astype(float)) / (band_nir.astype(float) + band_red.astype(float) + 0.428) * (1.428)   \n",
    "                     ndmi = (band_nir.astype(float) - band_swir.astype(float)) / (band_nir.astype(float) + band_swir.astype(float)) \n",
    "                  \n",
    "                     # Set spatial characteristics of the output object to mirror the input\n",
    "                     kwargs = src.meta\n",
    "                     kwargs.update(\n",
    "                             dtype=rasterio.float32,\n",
    "                             count = 1)\n",
    "                        \n",
    "                     # Create the files\n",
    "                     with rasterio.open(output_ndvi, 'w', **kwargs) as dst:\n",
    "                         dst.write_band(1, ndvi.astype(rasterio.float32))\n",
    "                        \n",
    "                     with rasterio.open(output_savi, 'w', **kwargs) as dst:\n",
    "                         dst.write_band(1, savi.astype(rasterio.float32))\n",
    "                                \n",
    "                     with rasterio.open(output_ndmi, 'w', **kwargs) as dst:\n",
    "                         dst.write_band(1, ndmi.astype(rasterio.float32))\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(10)) as pool:\n",
    "        return pool.map(calc_indices, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an annual raster stack of NDVI, SAVI, NDMI for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG NDVI 128\n",
      "30SWG SAVI 128\n",
      "30SWG NDMI 128\n",
      "30SWH NDVI 130\n",
      "30SWH SAVI 130\n",
      "30SWH NDMI 130\n",
      "30SXG NDVI 114\n",
      "30SXG SAVI 114\n",
      "30SXG NDMI 114\n",
      "30SXH NDVI 118\n",
      "30SXH SAVI 118\n",
      "30SXH NDMI 118\n",
      "30SXJ NDVI 119\n",
      "30SXJ SAVI 119\n",
      "30SXJ NDMI 119\n",
      "30SYH NDVI 120\n",
      "30SYH SAVI 120\n",
      "30SYH NDMI 120\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stack_indices(tile):\n",
    "    for index in indices:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/*/*{index}.tif')\n",
    "        print(tile, index, len(file_list))\n",
    "      \n",
    "        with rasterio.open(file_list[0]) as src0:\n",
    "                meta = src0.meta\n",
    "        \n",
    "        meta.update(count = len(file_list))\n",
    "        \n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}.tif'\n",
    "\n",
    "        if not path.isfile(output):\n",
    "            with rasterio.open(output, 'w', **meta) as dst:\n",
    "                for id, layer in enumerate(file_list, start=1):\n",
    "                    with rasterio.open(layer) as src1:\n",
    "                        dst.write_band(id, src1.read(1))\n",
    "                        meta = src1.meta\n",
    "                        print(id, src1)\n",
    "                print(output)\n",
    "                \n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(stack_indices, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip the raster stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG NDVI 1\n",
      "30SWG SAVI 1\n",
      "30SWG NDMI 1\n",
      "30SWH NDVI 1\n",
      "30SWH SAVI 1\n",
      "30SWH NDMI 1\n",
      "30SXG NDVI 1\n",
      "30SXG SAVI 1\n",
      "30SXG NDMI 1\n",
      "30SXH NDVI 1\n",
      "30SXH SAVI 1\n",
      "30SXH NDMI 1\n",
      "30SXJ NDVI 1\n",
      "30SXJ SAVI 1\n",
      "30SXJ NDMI 1\n",
      "30SYH NDVI 1\n",
      "30SYH SAVI 1\n",
      "30SYH NDMI 1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with fiona.open('../Data/AOI/Rio_Segura_AOI_Tighter25830.geojson', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    \n",
    "def clip_raster(tile):\n",
    "    for index in indices:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}.tif')\n",
    "        print(tile, index, len(file_list))\n",
    "        for id, layer in enumerate(file_list, start=1):\n",
    "            output = f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_clip.tif'\n",
    "            if not path.isfile(output):\n",
    "                print(output)\n",
    "                with rasterio.open(layer) as src:\n",
    "                    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "                    out_meta = src.meta\n",
    "\n",
    "                # Save clipped imagery and change dtype\n",
    "                out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform,\n",
    "                         'dtype': 'float32',\n",
    "                         'compress':'lzw'})\n",
    "\n",
    "                with rasterio.open(output, \"w\", **out_meta) as dest:\n",
    "                    dest.nodata = 0\n",
    "                    dest.write(out_image)\n",
    "                    print(output)\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(clip_raster, tiles)\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG NDVI 1\n",
      "30SWG SAVI 1\n",
      "30SWG NDMI 1\n",
      "30SWH NDVI 1\n",
      "30SWH SAVI 1\n",
      "30SWH NDMI 1\n",
      "30SXG NDVI 1\n",
      "30SXG SAVI 1\n",
      "30SXG NDMI 1\n",
      "30SXH NDVI 1\n",
      "30SXH SAVI 1\n",
      "30SXH NDMI 1\n",
      "30SXJ NDVI 1\n",
      "30SXJ SAVI 1\n",
      "30SXJ NDMI 1\n",
      "30SYH NDVI 1\n",
      "30SYH SAVI 1\n",
      "30SYH NDMI 1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def percentile(tile):\n",
    "    for index in indices:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}.tif')\n",
    "        print(tile, index, len(file_list))\n",
    "        for percentile in percetiles:\n",
    "            output = f'../Data/Crop_Classification/S2/{year}/{tile}/{index}_p{percentile}.tif' \n",
    "            if not path.isfile(output):\n",
    "                print(percentile)\n",
    "                ds  = xr.open_rasterio(file_list[0])\n",
    "                percentil = ds.quantile(percentile/100, dim='band') \n",
    "                print(percentile/100)\n",
    "                print(output)\n",
    "                percentil.rio.to_raster(output)\n",
    "                input_raster = gdal.Open(output)\n",
    "                gdal.Warp(output, input_raster, dstSRS=\"EPSG:25830\")\n",
    "    \n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(percentile, tiles)\n",
    "         \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check all percentile raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG 0\n",
      "30SWH 0\n",
      "30SXG 0\n",
      "30SXH 0\n",
      "30SXJ 0\n",
      "30SYH 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tile in tiles:\n",
    "    list = []\n",
    "    for index in indices:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{index}_p*_UTM30.tif')\n",
    "        list.extend(file_list)      \n",
    "    print(tile, len(list))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster stack of Q3 NDVI and SAVI (Jul, Aug, Sep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG NDVI 37\n",
      "30SWG SAVI 37\n",
      "30SWH NDVI 37\n",
      "30SWH SAVI 37\n",
      "30SXG NDVI 35\n",
      "30SXG SAVI 35\n",
      "30SXH NDVI 35\n",
      "30SXH SAVI 35\n",
      "30SXJ NDVI 36\n",
      "30SXJ SAVI 36\n",
      "30SYH NDVI 34\n",
      "30SYH SAVI 34\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stack_indices_q3(tile):\n",
    "    for index in indices_Q3:\n",
    "        list = []\n",
    "        for month in Q3:\n",
    "            file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/*{index}.tif')\n",
    "            list.extend(file_list)    \n",
    "        print(tile, index, len(list))\n",
    "        with rasterio.open(list[0]) as src0:\n",
    "            meta = src0.meta\n",
    "        meta.update(count = len(list))\n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_q3.tif'\n",
    "        if not path.isfile(output):\n",
    "            with rasterio.open(output, 'w', **meta) as dst:\n",
    "                 for id, layer in enumerate(list, start=1):\n",
    "                    with rasterio.open(layer) as src1:\n",
    "                        dst.write_band(id, src1.read(1))\n",
    "                    print(output)\n",
    "                \n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(stack_indices_q3, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median raster from raster stack of  Q3 NDVI and SAVI (Jul, Aug, Sep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG NDVI 1\n",
      "30SWG SAVI 1\n",
      "30SWH NDVI 1\n",
      "30SWH SAVI 1\n",
      "30SXG NDVI 1\n",
      "30SXG SAVI 1\n",
      "30SXH NDVI 1\n",
      "30SXH SAVI 1\n",
      "30SXJ NDVI 1\n",
      "30SXJ SAVI 1\n",
      "30SYH NDVI 1\n",
      "30SYH SAVI 1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def stack_indices_q3_median(tile):\n",
    "    for index in indices_Q3:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/*{index}_q3.tif')\n",
    "        print(tile, index, len(file_list))\n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/{index}_q3_median.tif'\n",
    "        if not path.isfile(output):\n",
    "            ds  = xr.open_rasterio(file_list[0])\n",
    "            mean = ds.mean(dim='band')\n",
    "            mean.rio.to_raster(output)   \n",
    "            print(output)\n",
    "            ds = gdal.Open(output, 1)\n",
    "            sr = osr.SpatialReference()\n",
    "            sr.ImportFromEPSG(25830)\n",
    "            ds.SetProjection(sr.ExportToWkt())\n",
    "            ds = None\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(stack_indices_q3_median, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of amp5095 Amplitude for SAVI, NDMI and NDVI, \n",
    " - savi_amp5095 = savi annual percentile 95 subtract percentile 50\n",
    " - ndvi_amp5095  = ndvi  annual percentile 95 subtract percentile 50\n",
    " - ndmi_amp5095  = ndvi  annual percentile 95 subtract percentile 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG NDVI\n",
      "30SWG SAVI\n",
      "30SWG NDMI\n",
      "30SWH NDVI\n",
      "30SWH SAVI\n",
      "30SWH NDMI\n",
      "30SXG NDVI\n",
      "30SXG SAVI\n",
      "30SXG NDMI\n",
      "30SXH NDVI\n",
      "30SXH SAVI\n",
      "30SXH NDMI\n",
      "30SXJ NDVI\n",
      "30SXJ SAVI\n",
      "30SXJ NDMI\n",
      "30SYH NDVI\n",
      "30SYH SAVI\n",
      "30SYH NDMI\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def stack_amp5095(tile):\n",
    "    for index  in indices:\n",
    "        print(tile, index)\n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/{index}_amp5095.tif'   \n",
    "        if not path.isfile(output):\n",
    "            p95  = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_p95_UTM30.tif')\n",
    "            p50  = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_p50_UTM30.tif')\n",
    "            amp_5095 = xr.open_rasterio(p95[0]) - xr.open_rasterio(p50[0]) \n",
    "            amp_5095.rio.to_raster(output)\n",
    "            input_raster = gdal.Open(output)\n",
    "            gdal.Warp(output, input_raster, dstSRS=\"EPSG:25830\")\n",
    "            print(output)\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(stack_amp5095, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copernicus GLO-30 Digital Elevation Model resample to S2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def openRaster(raster):\n",
    "    closeOnExit = False\n",
    "    try:\n",
    "        raster.GetProjection()\n",
    "        openRaster = raster\n",
    "    except AttributeError:\n",
    "        openRaster = gdal.Open(raster)\n",
    "        closeOnExit = True\n",
    "    return openRaster, closeOnExit\n",
    "\n",
    "\n",
    "\n",
    "def getRasterInfo(raster):\n",
    "    r, closeOnExit = openRaster(raster)\n",
    "    proj = r.GetProjection()\n",
    "    gt = r.GetGeoTransform()\n",
    "    sizeX = r.RasterXSize\n",
    "    sizeY = r.RasterYSize\n",
    "    extent = [gt[0], gt[3]+gt[5]*sizeY, gt[0]+gt[1]*sizeX, gt[3]]\n",
    "    bands = r.RasterCount\n",
    "    if closeOnExit:\n",
    "        r = None\n",
    "  \n",
    "    return proj, gt, sizeX, sizeY, extent, \n",
    "\n",
    "def resampleWithGdalWarp(srcFile, templateFile, outFile=\"\", outFormat=\"MEM\",\n",
    "                         resampleAlg=\"average\"):\n",
    "    # Get template projection, extent and resolution\n",
    "    proj, gt, sizeX, sizeY, extent= getRasterInfo(templateFile)\n",
    "\n",
    "    # Resample with GDAL warp\n",
    "    outDs = gdal.Warp(outFile,\n",
    "                      srcFile,\n",
    "                      format=outFormat,\n",
    "                      dstSRS='EPSG:25830',\n",
    "                      xRes=gt[1],\n",
    "                      yRes=gt[5],\n",
    "                      outputBounds=extent,\n",
    "                      resampleAlg=resampleAlg)\n",
    "\n",
    "import gdal \n",
    "\n",
    "for tile in tiles:\n",
    "    templateFile = f'../Data/Crop_Classification/S2/{year}/{tile}/stack_NDMI_p90.tif'\n",
    "    glist = glob(f'../Data/Crop_Classification/elevation.tif')\n",
    "                 \n",
    "    for raster in glist:\n",
    "        output_file = os.path.join(os.path.dirname(raster),'S2', str(year), tile,'{}_20m.tif'.format(os.path.basename(raster).split('\\\\')[-1][:-4])) \n",
    "        if not path.isfile(output_file):\n",
    "            print(output_file)\n",
    "            resampleWithGdalWarp(raster, templateFile, outFile=output_file, outFormat=\"GTiff\", resampleAlg=\"average\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "../Data/Crop_Classification/S2/2021/elevation_GLO_25830.tif\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SWH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXG/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXH/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SXJ/elevation_20m.tif', '../Data/Crop_Classification/S2/2021/30SYH/elevation_20m.tif']\n"
     ]
    }
   ],
   "source": [
    "for month in months:\n",
    "    src_files_to_mosaic = []\n",
    "    month_tiles_list = glob(f'../Data/Crop_Classification/S2/{year}/*/elevation_20m.tif')\n",
    "    print(month_tiles_list)\n",
    "    for file_month in month_tiles_list:\n",
    "        src = rasterio.open(file_month)\n",
    "        src_files_to_mosaic.append(src) \n",
    "        \n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    profile = src.meta.copy()\n",
    "    profile.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans,\n",
    "                    \"compress\": \"lzw\"})\n",
    "    \n",
    "\n",
    "    out_file  = f'../Data/Crop_Classification/S2/{year}/elevation_GLO_25830.tif'\n",
    "    \n",
    "    if not path.isfile(out_file):\n",
    "        with rasterio.open(out_file, \"w\", **profile) as dest:\n",
    "            print(out_file)\n",
    "            dest.write(mosaic)\n",
    "            \n",
    "    ds = gdal.Open(out_file, 1)\n",
    "    sr = osr.SpatialReference()\n",
    "    sr.ImportFromEPSG(25830)\n",
    "    ds.SetProjection(sr.ExportToWkt())\n",
    "    ds = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate indices: HP_prob, CO_prob, AyF_prob\n",
    " - HP_prob (savi_amp5095, ndvi_p10)\n",
    "      -  HP_prop = expression('1 / (1 + exp(- (-2.37 + (-8.19 * savi_amp5095) + (7.084 * ndvi_p10)))))\n",
    "          - savi_amp5095 = savi annual percentile 95 subtract percentile 50\n",
    "     \n",
    "\n",
    " - CO_prob (ndmi_p90, elevation), \n",
    "     -  CO_prob = expression('1 / (1 + exp(- (0.11 + (-7.5 * ndmi_p90) + (0.006 * elevation)))))\n",
    "     \n",
    "\n",
    " - AyF_prob(ndmi_p95, ndvi_p95, elevation)\n",
    "     - AyF_prob = expression('1 / (1 + exp(- (0.05 + (1.5 * ndmi_p95) + (3.08 * ndvi_p95) + (-0.003 * elevation))))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG HP\n",
      "30SWG CO\n",
      "30SWG AyF\n",
      "30SWH HP\n",
      "30SWH CO\n",
      "30SWH AyF\n",
      "30SXG HP\n",
      "30SXG CO\n",
      "30SXG AyF\n",
      "30SXH HP\n",
      "30SXH CO\n",
      "30SXH AyF\n",
      "30SXJ HP\n",
      "30SXJ CO\n",
      "30SXJ AyF\n",
      "30SYH HP\n",
      "30SYH CO\n",
      "30SYH AyF\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indices_prob = ['HP', 'CO', 'AyF']\n",
    "\n",
    "def Prob_index(tile):\n",
    "    \n",
    "     for index  in indices_prob:\n",
    "        print(tile, index)\n",
    "        \n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/{index}_prob.tif'\n",
    "        \n",
    "        if not path.isfile(output):\n",
    "            \n",
    "            elev          = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/elevation_20m.tif')\n",
    "            savi_amp5095  = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/SAVI_amp5095.tif')\n",
    "            ndvi_p10      = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/NDVI_p10.tif')\n",
    "            ndvi_p95      = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/NDVI_p95.tif')\n",
    "            ndmi_p90      = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/NDMI_p90.tif')\n",
    "            ndmi_p95      = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/NDMI_p95.tif')\n",
    "\n",
    "            print(savi_amp5095, ndvi_p10, ndvi_p95, ndmi_p90, ndmi_p95, elev)\n",
    "\n",
    "            with rasterio.open(elev[0]) as src: elev = src.read(1)                             \n",
    "            with rasterio.open(savi_amp5095[0],'r+') as src: savi_amp5095 = src.read(1); src.nodata = 0   \n",
    "            with rasterio.open(ndvi_p10[0],'r+') as src: ndvi_p10 = src.read(1); src.nodata = 0\n",
    "            with rasterio.open(ndvi_p95[0],'r+') as src: ndvi_p95 = src.read(1); src.nodata = 0 \n",
    "            with rasterio.open(ndmi_p90[0],'r+') as src: ndmi_p90 = src.read(1); src.nodata = 0\n",
    "            with rasterio.open(ndmi_p95[0],'r+') as src: ndmi_p95 = src.read(1); src.nodata = 0\n",
    "\n",
    "            kwargs = src.meta \n",
    "            kwargs.update({\"driver\": \"GTiff\", 'compress':'lzw'})\n",
    "\n",
    "            if 'HP' == index:\n",
    "                data  = (1 / (1 + np.exp(- (-2.37 + (-8.19 * savi_amp5095.astype(float)) + (7.084 * ndvi_p10.astype(float))))))\n",
    "            if 'CO' == index:\n",
    "                data  = (1 / (1 + np.exp(- (0.11 + (-7.5 * ndmi_p90.astype(float)) + (0.006 * elev.astype(float))))))\n",
    "            if 'AyF' == index:\n",
    "                data  = (1 / (1 + np.exp(- (0.05 + (1.5 * ndmi_p95.astype(float)) + (3.08 * ndvi_p95.astype(float) + (-0.003 * elev.astype(float)))))))\n",
    "            \n",
    "            print(index, output)\n",
    "\n",
    "            with rasterio.open(output, 'w', **kwargs) as dst:\n",
    "                print('writing')\n",
    "                dst.nodata = 0\n",
    "                dst.write_band(1, data)\n",
    "            print('Reprojecting')    \n",
    "            ds = gdal.Open(output, 1)\n",
    "            sr = osr.SpatialReference()\n",
    "            sr.ImportFromEPSG(25830)\n",
    "            ds.SetProjection(sr.ExportToWkt())\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(Prob_index, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Density Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E31N17_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E31N18_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E32N16_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E32N17_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E32N18_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E33N16_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E33N17_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E33N18_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E34N17_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E34N18_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E30N16_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E30N17_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E30N18_03035_v020.tif', '../Data/Crop_Classification/forest_density_TCD/TCD_2018_010m_E31N16_03035_v020.tif']\n"
     ]
    }
   ],
   "source": [
    "src_files_to_mosaic = []\n",
    "month_tiles_list = glob(f'../Data/Crop_Classification/forest_density_TCD/*.tif')\n",
    "print(month_tiles_list)\n",
    "for file_month in month_tiles_list:\n",
    "    src = rasterio.open(file_month)\n",
    "    src_files_to_mosaic.append(src) \n",
    "    \n",
    "mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "profile = src.meta.copy()\n",
    "profile.update({\"driver\": \"GTiff\",\n",
    "                \"height\": mosaic.shape[1],\n",
    "                \"width\": mosaic.shape[2],\n",
    "                \"transform\": out_trans,\n",
    "                \"compress\": \"lzw\"})\n",
    "\n",
    "out_file  = f'../Data/Crop_Classification/forest_density_TCD.tif'\n",
    "\n",
    "if not path.isfile(out_file):\n",
    "    with rasterio.open(out_file, \"w\", **profile) as dest:\n",
    "        dest.write(mosaic)\n",
    "        \n",
    "input_ras = gdal.Open(out_file)\n",
    "output_ras = r'../Data/Crop_Classification/forest_density_TCD_25830.tif'\n",
    "options = gdal.WarpOptions(format = 'GTiff',  creationOptions = ['TFW=YES', 'COMPRESS=LZW'])\n",
    "\n",
    "warp = gdal.Warp(output_ras, input_ras, dstSRS='EPSG:25830', options = options)\n",
    "warp = None # Closes the files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitching all tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_des = [\n",
    "    'NDVI_q3_median',\n",
    "    'HP_prob',\n",
    "    'SAVI_q3_median',\n",
    "    'SAVI_amp5095',\n",
    "    'NDVI_amp5095',\n",
    "    'NDVI_p10',\n",
    "    'SAR20_HV',\n",
    "    'CO_prob',\n",
    "    'AyF_prob',\n",
    "    'NDVI_p20',\n",
    "    'EOSD_20m',\n",
    "    'elevation',\n",
    "    'SAVI_p10',\n",
    "    'NDMI_p95',\n",
    "    'SAVI_p20',\n",
    "    'forest_density_TCD',\n",
    "    'NDMI_amp5095'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_q3_median 6\n",
      "HP_prob 6\n",
      "SAVI_q3_median 6\n",
      "SAVI_amp5095 6\n",
      "NDVI_amp5095 6\n",
      "NDVI_p10 6\n",
      "SAR20_HV 0\n",
      "CO_prob 6\n",
      "AyF_prob 6\n",
      "NDVI_p20 6\n",
      "EOSD_20m 0\n",
      "elevation 0\n",
      "SAVI_p10 6\n",
      "NDMI_p95 6\n",
      "SAVI_p20 6\n",
      "forest_density_TCD 0\n",
      "NDMI_amp5095 6\n"
     ]
    }
   ],
   "source": [
    "for variable in variables_des:\n",
    "    src_files_to_mosaic = []\n",
    "    var_list = glob(f'../Data/Crop_Classification/S2/{year}/*/{variable}.tif')\n",
    "    print(variable, len(var_list))\n",
    "    \n",
    "    out_file  = f'../Data/Crop_Classification/{variable}.tif'\n",
    "    \n",
    "    if not path.isfile(out_file):\n",
    "        if var_list:\n",
    "            for var in var_list:\n",
    "                src = rasterio.open(var)\n",
    "                src_files_to_mosaic.append(src) \n",
    "        \n",
    "            mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "    \n",
    "            profile = src.meta.copy()\n",
    "            profile.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": mosaic.shape[1],\n",
    "                        \"width\": mosaic.shape[2],\n",
    "                        \"transform\": out_trans,\n",
    "                        \"compress\": \"lzw\"})\n",
    "        \n",
    "            with rasterio.open(out_file, \"w\", **profile) as dest:\n",
    "                print(out_file)\n",
    "                dest.write(mosaic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a stack of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "list_variables = glob(f'../Data/Crop_Classification/*.tif')\n",
    "print(len(list_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/elevation_GLO_25830.tif\n",
      "../Data/Crop_Classification/SAR20_HV.tif\n",
      "../Data/Crop_Classification/EOSD_20m.tif\n",
      "../Data/Crop_Classification/forest_density_TCD.tif\n",
      "../Data/Crop_Classification/NDVI_q3_median.tif\n",
      "../Data/Crop_Classification/HP_prob.tif\n",
      "../Data/Crop_Classification/SAVI_q3_median.tif\n",
      "../Data/Crop_Classification/SAVI_amp5095.tif\n",
      "../Data/Crop_Classification/NDVI_amp5095.tif\n",
      "../Data/Crop_Classification/NDVI_p10.tif\n",
      "../Data/Crop_Classification/CO_prob.tif\n",
      "../Data/Crop_Classification/AyF_prob.tif\n",
      "../Data/Crop_Classification/NDVI_p20.tif\n",
      "../Data/Crop_Classification/SAVI_p10.tif\n",
      "../Data/Crop_Classification/NDMI_p95.tif\n",
      "../Data/Crop_Classification/SAVI_p20.tif\n",
      "../Data/Crop_Classification/NDMI_amp5095.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read metadata of first file\n",
    "with rasterio.open(list_variables[0]) as src0:\n",
    "    meta = src0.meta\n",
    "\n",
    "# Update meta to reflect the number of layers\n",
    "meta.update(count = len(list_variables),compress ='lzw', dtype= rasterio.float32)\n",
    "\n",
    "# Read each layer and write it to stack\n",
    "out_file = '../Data/Crop_Classification/Variables/Variables.tif'\n",
    "if not path.isfile(out_file):\n",
    "    with rasterio.open(out_file, 'w', **meta) as dst:\n",
    "        for id, layer in enumerate(list_variables, start=1):\n",
    "            with rasterio.open(layer) as src:\n",
    "                print(layer)\n",
    "                src = src.read(1).astype(np.float32)\n",
    "                dst.write_band(id, src)\n",
    "                dst.set_band_description(id, os.path.basename(layer).split()[-1][:-4])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample raster to 10m for statistics (getting values for smaller parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input and output filenames\n",
    "inputFile = '../Data/Crop_Classification/Variables/Variables.tif'\n",
    "outputFile = '../Data/Crop_Classification/Variables/Variables_10.tif'\n",
    "\n",
    "import gdal\n",
    "\n",
    "\n",
    "xres=10\n",
    "yres=10\n",
    "resample_alg = 'near'\n",
    "\n",
    "options = gdal.WarpOptions(xRes=xres, yRes=yres, resampleAlg=resample_alg, creationOptions = ['TFW=YES', 'COMPRESS=LZW'])\n",
    "\n",
    "\n",
    "ds = gdal.Warp(outputFile, inputFile, options=options)\n",
    "ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = tuple(['elevation_GLO',\n",
    " 'SAR20_HV',\n",
    " 'EOSD_20m',\n",
    " 'forest_density_TCD',\n",
    " 'NDVI_q3_median',\n",
    " 'HP_prob',\n",
    " 'SAVI_q3_median',\n",
    " 'SAVI_amp5095',\n",
    " 'NDVI_amp5095',\n",
    " 'NDVI_p10',\n",
    " 'CO_prob',\n",
    " 'AyF_prob',\n",
    " 'NDVI_p20',\n",
    " 'SAVI_p10',\n",
    " 'NDMI_p95',\n",
    " 'SAVI_p20',\n",
    " 'NDMI_amp5095'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Shape file\n",
    "with fiona.open('../Data/Crop_Classification/Crop_parcel_2021/Cultivos_regados_AH2021_v6_20.shp', \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    print('Shape file Projection: ', shapefile.crs)\n",
    "\n",
    "    \n",
    "with rasterio.open('../Data/Crop_Classification/Variables/Variables.tif') as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta.copy()\n",
    "\n",
    "# Save clipped imagery and change dtype\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform,\n",
    "                 'dtype': 'float32',\n",
    "                 'compress': \"lzw\",\n",
    "                 'nodata':0})\n",
    "\n",
    "print(out_meta)\n",
    "\n",
    "img_trans_clip = os.path.join('../Data/Crop_Classification/Variables/Variables_clip.tif')   \n",
    "with rasterio.open(img_trans_clip, \"w\", **out_meta) as dest:\n",
    "    dest.descriptions = bands\n",
    "    dest.write(out_image)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zonal statistics -  app. 2-3h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elevation_GLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAR20_HV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOSD_20m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forest_density_TCD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_q3_median\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HP_prob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVI_q3_median\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVI_amp5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_amp5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_p10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO_prob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AyF_prob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI_p20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVI_p10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDMI_p95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVI_p20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDMI_amp5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ansu\\Miniconda3\\lib\\site-packages\\rasterstats\\io.py:313: UserWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\"Setting nodata to -999; specify nodata explicitly\")\n"
     ]
    }
   ],
   "source": [
    "gdf_parcels = gpd.read_file(parcels)\n",
    "\n",
    "output_stat_var = '../Data/Crop_Classification/Variables/crop_stat_median.geojson'\n",
    "\n",
    "if not path.isfile(output_stat_var):\n",
    "      with rasterio.open('../Data/Crop_Classification/Variables/Variables_clip.tif') as src:\n",
    "            \n",
    "            # Calculate statistics for each band\n",
    "            df_var = pd. DataFrame()\n",
    "            affine = src.transform\n",
    "            for band_nr, band_name in enumerate(bands, start=1):\n",
    "                  array = src.read(band_nr)\n",
    "                  print(band_name)\n",
    "                  df_zonal_stats = pd.DataFrame(zonal_stats(gdf_parcels, array, affine=affine, stats=\"median\"))\n",
    "                  df = df_zonal_stats.rename(columns={'median': f'median_{band_name}'})\n",
    "                  df_var = pd.concat([df_var, df], axis=1) \n",
    "\n",
    "      gdf_stat_var = pd.concat([gdf_parcels, df_var], axis=1) \n",
    "      gdf_stat_var.to_file(output_stat_var, driver=\"GeoJSON\") \n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly NDVI and Zonal_stat\n",
    "- monthly NDVI for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices               = ['NDVI'] \n",
    "\n",
    "\n",
    "def stack_indices(tile):\n",
    "    for index in indices:\n",
    "        for month in months:\n",
    "            file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/*{index}.tif')\n",
    "            print(tile, index, len(file_list), month)\n",
    "            output_stack= f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_M{month}.tif'\n",
    "\n",
    "            with rasterio.open(file_list[0]) as src0:\n",
    "                meta = src0.meta\n",
    "        \n",
    "            meta.update(count = len(file_list))\n",
    "        \n",
    "            if not path.isfile(output_stack):\n",
    "                with rasterio.open(output_stack, 'w', **meta) as dst:\n",
    "                    for id, layer in enumerate(file_list, start=1):\n",
    "                        with rasterio.open(layer) as src1:\n",
    "                            dst.write_band(id, src1.read(1))\n",
    "                            meta = src1.meta\n",
    "                            print(id, src1)\n",
    "            print('Done', output_stack)\n",
    "\n",
    "            output_mean = f'../Data/Crop_Classification/S2/{year}/{tile}/NDVI_M{month}_mean.tif'\n",
    "            output_stack= glob(f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_M{month}.tif')\n",
    "            \n",
    "            if not path.isfile(output_mean):\n",
    "                print('Working', output_mean)\n",
    "                ds  = xr.open_rasterio(output_stack[0])\n",
    "                mean = ds.mean(dim='band')\n",
    "                mean.rio.to_raster(output_mean)   \n",
    "                print(output_mean)\n",
    "                ds = gdal.Open(output_mean, 1)\n",
    "                sr = osr.SpatialReference()\n",
    "                sr.ImportFromEPSG(25830)\n",
    "                ds.SetProjection(sr.ExportToWkt())\n",
    "                ds = None\n",
    "            \n",
    "            print('Done', output_mean)\n",
    "\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(stack_indices, tiles)\n",
    "        \n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge all tiles together for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    src_files_to_mosaic = []\n",
    "    month_tiles_list = glob(f'../Data/Crop_Classification/S2/{year}/*/NDVI_M{month}_mean.tif')\n",
    "    print(month_tiles_list)\n",
    "    for file_month in month_tiles_list:\n",
    "        src = rasterio.open(file_month)\n",
    "        src_files_to_mosaic.append(src) \n",
    "        \n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    profile = src.meta.copy()\n",
    "    profile.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans,\n",
    "                    \"compress\": \"lzw\"})\n",
    "    \n",
    "    \n",
    "    out_file  = f'../Data/Crop_Classification/S2/{year}/NDVI_M{month}_mean.tif'\n",
    "    \n",
    "    if not path.isfile(out_file):\n",
    "        with rasterio.open(out_file, \"w\", **profile) as dest:\n",
    "            print(out_file)\n",
    "            dest.write(mosaic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a stack of monthly NDVI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_NDVI = glob(f'../Data/Crop_Classification/S2/{year}/NDVI_M*_mean.tif')\n",
    "print(list_NDVI, len(list_NDVI))\n",
    "      \n",
    "with rasterio.open(list_NDVI[0]) as src0:\n",
    "    meta = src0.meta\n",
    "    meta.update(count = len(list_NDVI))\n",
    "        \n",
    "    output = f'../Data/Crop_Classification/S2/{year}/stack_month_NDVI.tif'\n",
    "\n",
    "    if not path.isfile(output):\n",
    "        with rasterio.open(output, 'w', **meta) as dst:\n",
    "            for id, layer in enumerate(list_NDVI, start=1):\n",
    "                    with rasterio.open(layer) as src1:\n",
    "                        dst.write_band(id, src1.read(1))\n",
    "                        meta = src1.meta\n",
    "                        print(id, src1)\n",
    "                    \n",
    "print(output)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Zonal Stats NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_stat_NDVI = '../Data/Crop_Classification/Variables/crop_stat_NDVI_median.geojson'\n",
    "\n",
    "if not path.isfile(output_stat_NDVI):\n",
    "      with rasterio.open(f'../Data/Crop_Classification/S2/{year}/stack_month_NDVI.tif') as src:\n",
    "            df_stat_NDVI = pd. DataFrame()\n",
    "            affine = src.transform\n",
    "            for band in range(1, src.count+1):\n",
    "                  print(band)\n",
    "                  array = src.read(band)\n",
    "                  df_zonal_stats = pd.DataFrame(zonal_stats(gdf_parcels, array, affine=affine, stats=\"median\"))\n",
    "                  df = df_zonal_stats.rename(columns={'median': f'median_{band}'})\n",
    "                  df_stat_NDVI = pd.concat([df_stat_NDVI, df], axis=1)\n",
    "\n",
    "      gdf_stat_NDVI = pd.concat([gdf_parcels, df_stat_NDVI], axis=1) \n",
    "      gdf_stat_NDVI.to_file(output_stat_NDVI, driver=\"GeoJSON\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge two data frames & Reclass to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_1</th>\n",
       "      <th>max_1</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>count_1</th>\n",
       "      <th>median_1</th>\n",
       "      <th>min_2</th>\n",
       "      <th>max_2</th>\n",
       "      <th>mean_2</th>\n",
       "      <th>count_2</th>\n",
       "      <th>median_2</th>\n",
       "      <th>...</th>\n",
       "      <th>min_11</th>\n",
       "      <th>max_11</th>\n",
       "      <th>mean_11</th>\n",
       "      <th>count_11</th>\n",
       "      <th>median_11</th>\n",
       "      <th>min_12</th>\n",
       "      <th>max_12</th>\n",
       "      <th>mean_12</th>\n",
       "      <th>count_12</th>\n",
       "      <th>median_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030795</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>0.276709</td>\n",
       "      <td>0.276709</td>\n",
       "      <td>0.276709</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272253</td>\n",
       "      <td>0.272253</td>\n",
       "      <td>0.272253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.272253</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.241663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>0.233891</td>\n",
       "      <td>0.233891</td>\n",
       "      <td>0.233891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236289</td>\n",
       "      <td>0.236289</td>\n",
       "      <td>0.236289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236289</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>0.191431</td>\n",
       "      <td>1</td>\n",
       "      <td>0.191431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068394</td>\n",
       "      <td>0.068394</td>\n",
       "      <td>0.068394</td>\n",
       "      <td>1</td>\n",
       "      <td>0.068394</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>1</td>\n",
       "      <td>0.388719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415532</td>\n",
       "      <td>0.415532</td>\n",
       "      <td>0.415532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415532</td>\n",
       "      <td>0.390508</td>\n",
       "      <td>0.390508</td>\n",
       "      <td>0.390508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.013076</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013076</td>\n",
       "      <td>0.274430</td>\n",
       "      <td>0.366182</td>\n",
       "      <td>0.320306</td>\n",
       "      <td>2</td>\n",
       "      <td>0.320306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359775</td>\n",
       "      <td>0.441085</td>\n",
       "      <td>0.400430</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400430</td>\n",
       "      <td>0.372625</td>\n",
       "      <td>0.401080</td>\n",
       "      <td>0.386852</td>\n",
       "      <td>2</td>\n",
       "      <td>0.386852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102683</td>\n",
       "      <td>0.102683</td>\n",
       "      <td>0.102683</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102683</td>\n",
       "      <td>0.293749</td>\n",
       "      <td>0.293749</td>\n",
       "      <td>0.293749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.293749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414202</td>\n",
       "      <td>0.414202</td>\n",
       "      <td>0.414202</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414202</td>\n",
       "      <td>0.296779</td>\n",
       "      <td>0.296779</td>\n",
       "      <td>0.296779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277690</th>\n",
       "      <td>0.074856</td>\n",
       "      <td>0.553023</td>\n",
       "      <td>0.234221</td>\n",
       "      <td>485</td>\n",
       "      <td>0.232465</td>\n",
       "      <td>0.093028</td>\n",
       "      <td>0.438367</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>485</td>\n",
       "      <td>0.232324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026521</td>\n",
       "      <td>0.540800</td>\n",
       "      <td>0.189617</td>\n",
       "      <td>485</td>\n",
       "      <td>0.158832</td>\n",
       "      <td>0.028204</td>\n",
       "      <td>0.437217</td>\n",
       "      <td>0.145971</td>\n",
       "      <td>485</td>\n",
       "      <td>0.124439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277691</th>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.272912</td>\n",
       "      <td>0.167172</td>\n",
       "      <td>184</td>\n",
       "      <td>0.166608</td>\n",
       "      <td>0.089788</td>\n",
       "      <td>0.259710</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>184</td>\n",
       "      <td>0.150723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.465226</td>\n",
       "      <td>0.295388</td>\n",
       "      <td>184</td>\n",
       "      <td>0.301257</td>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.358792</td>\n",
       "      <td>0.138840</td>\n",
       "      <td>184</td>\n",
       "      <td>0.133257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277692</th>\n",
       "      <td>0.084880</td>\n",
       "      <td>0.246004</td>\n",
       "      <td>0.170934</td>\n",
       "      <td>141</td>\n",
       "      <td>0.178115</td>\n",
       "      <td>0.074776</td>\n",
       "      <td>0.227954</td>\n",
       "      <td>0.145286</td>\n",
       "      <td>141</td>\n",
       "      <td>0.143732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138066</td>\n",
       "      <td>0.736644</td>\n",
       "      <td>0.480189</td>\n",
       "      <td>141</td>\n",
       "      <td>0.500174</td>\n",
       "      <td>0.068730</td>\n",
       "      <td>0.357981</td>\n",
       "      <td>0.223747</td>\n",
       "      <td>141</td>\n",
       "      <td>0.225438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277693</th>\n",
       "      <td>0.106953</td>\n",
       "      <td>0.248247</td>\n",
       "      <td>0.173538</td>\n",
       "      <td>82</td>\n",
       "      <td>0.171182</td>\n",
       "      <td>0.103406</td>\n",
       "      <td>0.204252</td>\n",
       "      <td>0.144590</td>\n",
       "      <td>82</td>\n",
       "      <td>0.142682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236769</td>\n",
       "      <td>0.778121</td>\n",
       "      <td>0.484831</td>\n",
       "      <td>82</td>\n",
       "      <td>0.478351</td>\n",
       "      <td>0.125544</td>\n",
       "      <td>0.397986</td>\n",
       "      <td>0.223838</td>\n",
       "      <td>82</td>\n",
       "      <td>0.217429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277694</th>\n",
       "      <td>0.071452</td>\n",
       "      <td>0.181637</td>\n",
       "      <td>0.130948</td>\n",
       "      <td>85</td>\n",
       "      <td>0.125239</td>\n",
       "      <td>0.059689</td>\n",
       "      <td>0.138746</td>\n",
       "      <td>0.107897</td>\n",
       "      <td>85</td>\n",
       "      <td>0.108916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158727</td>\n",
       "      <td>0.309196</td>\n",
       "      <td>0.252287</td>\n",
       "      <td>85</td>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.208485</td>\n",
       "      <td>0.147278</td>\n",
       "      <td>85</td>\n",
       "      <td>0.136675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>277695 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           min_1     max_1    mean_1  count_1  median_1     min_2     max_2  \\\n",
       "0       0.030795  0.030795  0.030795        1  0.030795  0.276709  0.276709   \n",
       "1      -0.000818 -0.000818 -0.000818        1 -0.000818  0.233891  0.233891   \n",
       "2       0.068394  0.068394  0.068394        1  0.068394  0.388719  0.388719   \n",
       "3       0.005493  0.020658  0.013076        2  0.013076  0.274430  0.366182   \n",
       "4       0.102683  0.102683  0.102683        1  0.102683  0.293749  0.293749   \n",
       "...          ...       ...       ...      ...       ...       ...       ...   \n",
       "277690  0.074856  0.553023  0.234221      485  0.232465  0.093028  0.438367   \n",
       "277691  0.088062  0.272912  0.167172      184  0.166608  0.089788  0.259710   \n",
       "277692  0.084880  0.246004  0.170934      141  0.178115  0.074776  0.227954   \n",
       "277693  0.106953  0.248247  0.173538       82  0.171182  0.103406  0.204252   \n",
       "277694  0.071452  0.181637  0.130948       85  0.125239  0.059689  0.138746   \n",
       "\n",
       "          mean_2  count_2  median_2  ...    min_11    max_11   mean_11  \\\n",
       "0       0.276709        1  0.276709  ...  0.272253  0.272253  0.272253   \n",
       "1       0.233891        1  0.233891  ...  0.236289  0.236289  0.236289   \n",
       "2       0.388719        1  0.388719  ...  0.415532  0.415532  0.415532   \n",
       "3       0.320306        2  0.320306  ...  0.359775  0.441085  0.400430   \n",
       "4       0.293749        1  0.293749  ...  0.414202  0.414202  0.414202   \n",
       "...          ...      ...       ...  ...       ...       ...       ...   \n",
       "277690  0.238600      485  0.232324  ...  0.026521  0.540800  0.189617   \n",
       "277691  0.156765      184  0.150723  ...  0.158556  0.465226  0.295388   \n",
       "277692  0.145286      141  0.143732  ...  0.138066  0.736644  0.480189   \n",
       "277693  0.144590       82  0.142682  ...  0.236769  0.778121  0.484831   \n",
       "277694  0.107897       85  0.108916  ...  0.158727  0.309196  0.252287   \n",
       "\n",
       "        count_11  median_11    min_12    max_12   mean_12  count_12  median_12  \n",
       "0              1   0.272253  0.241663  0.241663  0.241663         1   0.241663  \n",
       "1              1   0.236289  0.191431  0.191431  0.191431         1   0.191431  \n",
       "2              1   0.415532  0.390508  0.390508  0.390508         1   0.390508  \n",
       "3              2   0.400430  0.372625  0.401080  0.386852         2   0.386852  \n",
       "4              1   0.414202  0.296779  0.296779  0.296779         1   0.296779  \n",
       "...          ...        ...       ...       ...       ...       ...        ...  \n",
       "277690       485   0.158832  0.028204  0.437217  0.145971       485   0.124439  \n",
       "277691       184   0.301257  0.072706  0.358792  0.138840       184   0.133257  \n",
       "277692       141   0.500174  0.068730  0.357981  0.223747       141   0.225438  \n",
       "277693        82   0.478351  0.125544  0.397986  0.223838        82   0.217429  \n",
       "277694        85   0.250489  0.093333  0.208485  0.147278        85   0.136675  \n",
       "\n",
       "[277695 rows x 60 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_stat_NDVI.iloc[:, 21:81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stat_var = gpd.read_file(output_stat_var)\n",
    "gdf_stat_NDVI = gpd.read_file(output_stat_NDVI)\n",
    "\n",
    "\n",
    "# gdf_stat_var = gpd.read_file('../Data/Crop_Classification/Variables/crop_stat_median.geojson')\n",
    "# gdf_stat_NDVI = gpd.read_file('../Data/Crop_Classification/Variables/crop_stat_NDVI_median.geojson')\n",
    "\n",
    "gdf_stat_merge = pd.concat([gdf_stat_var, gdf_stat_NDVI.iloc[:, 21:81]], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stat_merge['Class_num'] = gdf_stat_merge['C_AH2021']\n",
    "gdf_stat_merge['Class_name'] = gdf_stat_merge['C_AH2021']\n",
    "gdf_stat_merge['Class'] = gdf_stat_merge['C_AH2021']\n",
    "\n",
    "\n",
    "gdf_stat_merge['Class_name'] = gdf_stat_merge['Class'].replace({'HU':'Family gardens' ,\n",
    "                                                                'HV':'Herbaceous irrigated in summer',\n",
    "                                                                'HV2':'Herbaceous with double harvest (including one in summer)',\n",
    "                                                                'HV3':'Herbaceous with triple harvest (including one in summer)',\n",
    "                                                                'HO':'Herbaceous irrigated in autumn',\n",
    "                                                                'H2':'Herbaceous with double harvest (outside summer)', \n",
    "                                                                'H3':'Herbaceous with triple harvest (outside summer)',\n",
    "                                                                'HI':'Young Herbaceous irrigated in winter',\n",
    "                                                                'HP':'Herbaceous irrigated in spring', \n",
    "                                                                'ALM':'Almonds',\n",
    "                                                                'INV':'Greenhouse',\n",
    "                                                                'CIT':'Citrus',\n",
    "                                                                'OV':'Olivos',\n",
    "                                                                'FJ':'Young Fruit',\n",
    "                                                                'LBC':'Low Density Tree Cover', \n",
    "                                                                'CITj':'Young Citrus',\n",
    "                                                                'VP':'Vineyard (table grape)',\n",
    "                                                                'FR':'Fruit', \n",
    "                                                                'V':'Vineyard'})\n",
    "\n",
    "gdf_stat_merge['Class_num'] = gdf_stat_merge['Class_num'].replace({'HU':'13' ,\n",
    "                                                                   'HV':'1',\n",
    "                                                                   'HV2':'1',\n",
    "                                                                   'HV3':'1',\n",
    "                                                                   'HO':'1',\n",
    "                                                                   'H2':'1', \n",
    "                                                                   'H3':'1',\n",
    "                                                                   'HI':'1',\n",
    "                                                                   'HP':'1', \n",
    "                                                                   'ALM':'6',\n",
    "                                                                   'INV':'9',\n",
    "                                                                   'CIT':'3',\n",
    "                                                                   'OV':'4',\n",
    "                                                                   'FRj':'10',\n",
    "                                                                   'LBC':'12', \n",
    "                                                                   'CITj':'11',\n",
    "                                                                   'VP':'8',\n",
    "                                                                   'FR':'2', \n",
    "                                                                   'V':'7'})\n",
    "                                             \n",
    " \n",
    "gdf_stat_merge.Class = np.where(((gdf_stat_merge.C21_M05.eq('LAC')) & (gdf_stat_merge.Class_name.eq('Olivos'))),'OV_LAC', gdf_stat_merge.Class)\n",
    "gdf_stat_merge.Class = np.where(((gdf_stat_merge.C21_M05.eq('LBC')) & (gdf_stat_merge.Class_name.eq('Olivos'))),'OV_LBC', gdf_stat_merge.Class)\n",
    "gdf_stat_merge.Class_num = np.where((gdf_stat_merge.Class.eq('OV_LBC')),'5', gdf_stat_merge.Class_num)\n",
    "gdf_stat_merge.Class_name = np.where((gdf_stat_merge.Class.eq('OV_LBC')),'Olivos LBC', gdf_stat_merge.Class_name)\n",
    "gdf_stat_merge.Class_name = np.where((gdf_stat_merge.Class.eq('OV_LAC')),'Olivos LAC', gdf_stat_merge.Class_name)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stat_merge.groupby('Class_num').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_stat_all = '../Data/Crop_Classification/Variables/crop_stat_all.geojson'\n",
    "gdf_stat_merge.to_file(output_stat_all, driver=\"GeoJSON\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional:  Calculation of Salinity index\n",
    "\n",
    "- Normalized Difference Salinity Index (NDSI), *Khan 2005*\n",
    "      -  ESI = expression((RED-NIR)/(RED+NIR)) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32ms:\\sulova\\9_Segura\\4_Analysis_II\\JupyterNotebook\\0_Crop_Preprocessinng.ipynb Cell 58\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/sulova/9_Segura/4_Analysis_II/JupyterNotebook/0_Crop_Preprocessinng.ipynb#X62sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m pool\u001b[39m.\u001b[39mmap(calc_salinity, tiles)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/sulova/9_Segura/4_Analysis_II/JupyterNotebook/0_Crop_Preprocessinng.ipynb#X62sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/sulova/9_Segura/4_Analysis_II/JupyterNotebook/0_Crop_Preprocessinng.ipynb#X62sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     results \u001b[39m=\u001b[39m run(tiles)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/sulova/9_Segura/4_Analysis_II/JupyterNotebook/0_Crop_Preprocessinng.ipynb#X62sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDone\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiles' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def calc_salinity(tile):\n",
    "    for month in months:\n",
    "        files = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/*REFL.tif')\n",
    "        for file in files:   \n",
    "            \n",
    "            output_esi = ('{}_ESI.tif'.format(file.split('\\\\')[-1][:-9]))\n",
    "        \n",
    "            if not path.isfile(output_esi):\n",
    "                with rasterio.open(file) as src: \n",
    "\n",
    "                    band_blue = src.read(1)/10000\n",
    "                    band_red  = src.read(3)/10000\n",
    "                    band_nir  = src.read(7)/10000\n",
    "\n",
    "                    esi =  (band_red.astype(float)-band_nir.astype(float)) / (band_red.astype(float)+band_nir.astype(float))\n",
    "                    kwargs = src.meta\n",
    "                    kwargs.update(dtype=rasterio.float32,count = 1, compres ='lzw')\n",
    "\n",
    "                    # Create the files\n",
    "                    with rasterio.open(output_esi, 'w', **kwargs) as dst:\n",
    "                        dst.write_band(1, esi.astype(rasterio.float32)) \n",
    "                    print(output_esi)\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(calc_salinity, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32ms:\\sulova\\9_Segura\\4_Analysis_II\\JupyterNotebook\\0_Crop_Preprocessinng.ipynb Cell 59\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/s%3A/sulova/9_Segura/4_Analysis_II/JupyterNotebook/0_Crop_Preprocessinng.ipynb#Y225sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output_esi \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_ESI.tif\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(file\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][:\u001b[39m-\u001b[39m\u001b[39m9\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Create a raster stack of ESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stack_esi(tile):\n",
    "    for month in months:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/*_ESI.tif')\n",
    "      \n",
    "        with rasterio.open(file_list[0]) as src0:\n",
    "                meta = src0.meta\n",
    "        \n",
    "        meta.update(count = len(file_list))\n",
    "        \n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/stack_month_{month}_ESI.tif'\n",
    "\n",
    "        if not path.isfile(output):\n",
    "            with rasterio.open(output, 'w', **meta) as dst:\n",
    "                for id, layer in enumerate(file_list, start=1):\n",
    "                    with rasterio.open(layer) as src1:\n",
    "                        dst.write_band(id, src1.read(1))\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(2)) as pool:\n",
    "        return pool.map(stack_esi, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculation of median per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sal_median (tile):\n",
    "    for month in months:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/stack_month_{month}_ESI.tif')\n",
    "        output = f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/month_{month}_ESI_median.tif'\n",
    "        \n",
    "        if not path.isfile(output):\n",
    "            ds  = xr.open_rasterio(file_list[0])\n",
    "            mean = ds.mean(dim='band')\n",
    "            mean = mean.rio.write_crs(25830, inplace=True)   \n",
    "            mean.rio.to_raster(output,compress='lzw')   \n",
    "    \n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(sal_median, tiles)\n",
    "         \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check all stack raster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30SWG 12\n",
      "30SWH 12\n",
      "30SXG 12\n",
      "30SXH 12\n",
      "30SXJ 12\n",
      "30SYH 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tile in tiles:\n",
    "    list = []\n",
    "    for month in months:\n",
    "        file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/month_{month}_ESI_median.tif')\n",
    "        list.extend(file_list)      \n",
    "    print(tile, len(list))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge all tiles together for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Data/Crop_Classification/S2/2021/30SWG/01/month_01_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/01/month_01_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/01/month_01_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/01/month_01_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/01/month_01_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/01/month_01_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/02/month_02_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/02/month_02_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/02/month_02_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/02/month_02_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/02/month_02_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/02/month_02_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/03/month_03_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/03/month_03_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/03/month_03_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/03/month_03_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/03/month_03_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/03/month_03_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/04/month_04_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/04/month_04_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/04/month_04_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/04/month_04_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/04/month_04_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/04/month_04_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/05/month_05_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/05/month_05_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/05/month_05_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/05/month_05_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/05/month_05_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/05/month_05_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/06/month_06_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/06/month_06_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/06/month_06_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/06/month_06_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/06/month_06_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/06/month_06_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/07/month_07_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/07/month_07_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/07/month_07_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/07/month_07_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/07/month_07_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/07/month_07_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/08/month_08_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/08/month_08_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/08/month_08_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/08/month_08_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/08/month_08_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/08/month_08_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/09/month_09_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/09/month_09_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/09/month_09_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/09/month_09_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/09/month_09_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/09/month_09_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/10/month_10_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/10/month_10_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/10/month_10_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/10/month_10_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/10/month_10_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/10/month_10_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/11/month_11_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/11/month_11_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/11/month_11_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/11/month_11_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/11/month_11_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/11/month_11_ESI_median.tif']\n",
      "['../Data/Crop_Classification/S2/2021/30SWG/12/month_12_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SWH/12/month_12_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXG/12/month_12_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXH/12/month_12_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SXJ/12/month_12_ESI_median.tif', '../Data/Crop_Classification/S2/2021/30SYH/12/month_12_ESI_median.tif']\n"
     ]
    }
   ],
   "source": [
    "for month in months:\n",
    "    src_files_to_mosaic = []\n",
    "    month_tiles_list = glob(f'../Data/Crop_Classification/S2/{year}/*/{month}/month_{month}_ESI_median.tif')\n",
    "    print(month_tiles_list)\n",
    "    for file_month in month_tiles_list:\n",
    "        src = rasterio.open(file_month)\n",
    "        src_files_to_mosaic.append(src) \n",
    "        \n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    profile = src.meta.copy()\n",
    "    profile.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans,\n",
    "                    \"compress\": \"lzw\"})\n",
    "    \n",
    "\n",
    "    out_file  = f'../Data/Crop_Classification/S2/{year}/salinity/ESI_{month}_{year}.tif'\n",
    "    \n",
    "    if not path.isfile(out_file):\n",
    "        with rasterio.open(out_file, \"w\", **profile) as dest:\n",
    "            print(out_file)\n",
    "            dest.write(mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clip a Salinity Month raster by a tighter area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_01_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_02_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_03_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_04_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_05_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_06_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_07_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_08_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_09_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_10_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_11_2021.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_12_2021.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "option = gdal.WarpOptions(cutlineDSName='../Data/AOI/Rio_Segura_AOI_Tighter25830.geojson', cropToCutline=True, dstNodata=0)\n",
    "\n",
    "for month in months:\n",
    "    files = glob(f'../Data/Crop_Classification/S2/2021/salinity/ESI_{month}_{year}.tif')\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        out_file =  f'../Data/Crop_Classification/S2/2021/salinity/ESI_{month}_{year}_clip.tif'\n",
    "        sr = osr.SpatialReference()\n",
    "        sr.ImportFromEPSG(25830)\n",
    "        ds = gdal.Open(file, 1)\n",
    "        ds.SetProjection(sr.ExportToWkt())\n",
    "        OutTile = gdal.Warp(f'../Data/Crop_Classification/S2/2021/salinity/ESI_{month}_{year}_clip.tif', ds, options=option)\n",
    "        OutTile = None\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clip by a Parcel SHP (10m buffer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buffer = 20\n",
    "\n",
    "output_parcel_buff = parcels[:-4] + f'_{buffer}.shp'\n",
    "parcels_gpd = gpd.read_file(parcels)\n",
    "print(output_parcel_buff)\n",
    "\n",
    "parcels_buffer= parcels_gpd.buffer(buffer)\n",
    "parcels_buffer.to_file(output_parcel_buff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:56800 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_01_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:59790 remote=tcp://127.0.0.1:32799>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:60012 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_02_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:49930 remote=tcp://127.0.0.1:40895>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_03_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:60628 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_04_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:60910 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_05_2021_parcel_10.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_06_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:33272 remote=tcp://127.0.0.1:32799>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:33292 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_07_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:51112 remote=tcp://127.0.0.1:40895>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:33562 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_08_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:56848 remote=tcp://127.0.0.1:42469>\n",
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:56882 remote=tcp://127.0.0.1:42469>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_09_2021_parcel_10.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.comm.tcp - WARNING - Closing dangling stream in <TCP local=tcp://127.0.0.1:34098 remote=tcp://127.0.0.1:32799>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/Crop_Classification/S2/2021/salinity/ESI_10_2021_parcel_10.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_11_2021_parcel_10.tif\n",
      "../Data/Crop_Classification/S2/2021/salinity/ESI_12_2021_parcel_10.tif\n"
     ]
    }
   ],
   "source": [
    "with fiona.open(output_parcel_buff, \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "\n",
    "for month in months:\n",
    "    files = glob(f'../Data/Crop_Classification/S2/2021/salinity/ESI_{month}_{year}.tif')\n",
    "    for file in files:\n",
    "        with rasterio.open(file) as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "            out_meta = src.meta\n",
    "            \n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "    out_file = f'../Data/Crop_Classification/S2/2021/salinity/ESI_{month}_{year}_parcel_10.tif'   \n",
    "\n",
    "        \n",
    "    with rasterio.open(out_file, \"w\", **out_meta) as dest:\n",
    "            dest.nodata = 0\n",
    "            dest.write(out_image)\n",
    "            \n",
    "    print(out_file)\n",
    "    ds = gdal.Open(out_file, 1)\n",
    "    sr = osr.SpatialReference()\n",
    "    sr.ImportFromEPSG(25830)\n",
    "    ds.SetProjection(sr.ExportToWkt())\n",
    "    ds = None\n",
    "    sr = None\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly NDVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- monthly NDVI for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices               = ['NDVI'] \n",
    "\n",
    "def stack_indices(tile):\n",
    "    for index in indices:\n",
    "        for month in months:\n",
    "            file_list = glob(f'../Data/Crop_Classification/S2/{year}/{tile}/{month}/*{index}.tif')\n",
    "            print(tile, index, len(file_list), month)\n",
    "            output_stack= f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_M{month}.tif'\n",
    "\n",
    "            with rasterio.open(file_list[0]) as src0:\n",
    "                meta = src0.meta\n",
    "        \n",
    "            meta.update(count = len(file_list))\n",
    "        \n",
    "            if not path.isfile(output_stack):\n",
    "                with rasterio.open(output_stack, 'w', **meta) as dst:\n",
    "                    for id, layer in enumerate(file_list, start=1):\n",
    "                        with rasterio.open(layer) as src1:\n",
    "                            dst.write_band(id, src1.read(1))\n",
    "                            meta = src1.meta\n",
    "                            print(id, src1)\n",
    "            print('Done', output_stack)\n",
    "\n",
    "            output_mean = f'../Data/Crop_Classification/S2/{year}/{tile}/NDVI_M{month}_mean.tif'\n",
    "            output_stack= glob(f'../Data/Crop_Classification/S2/{year}/{tile}/stack_{index}_M{month}.tif')\n",
    "            \n",
    "            if not path.isfile(output_mean):\n",
    "                print('Working', output_mean)\n",
    "                ds  = xr.open_rasterio(output_stack[0])\n",
    "                mean = ds.mean(dim='band')\n",
    "                mean.rio.to_raster(output_mean)   \n",
    "                print(output_mean)\n",
    "                ds = gdal.Open(output_mean, 1)\n",
    "                sr = osr.SpatialReference()\n",
    "                sr.ImportFromEPSG(25830)\n",
    "                ds.SetProjection(sr.ExportToWkt())\n",
    "                ds = None\n",
    "            \n",
    "            print('Done', output_mean)\n",
    "\n",
    "\n",
    "def run(tiles):\n",
    "    with ThreadPool(processes=int(1)) as pool:\n",
    "        return pool.map(stack_indices, tiles)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    results = run(tiles)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge all tiles together for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in months:\n",
    "    src_files_to_mosaic = []\n",
    "    month_tiles_list = glob(f'../Data/Crop_Classification/S2/{year}/*/NDVI_M{month}_mean.tif')\n",
    "    print(month_tiles_list)\n",
    "    for file_month in month_tiles_list:\n",
    "        src = rasterio.open(file_month)\n",
    "        src_files_to_mosaic.append(src) \n",
    "        \n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    profile = src.meta.copy()\n",
    "    profile.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans,\n",
    "                    \"compress\": \"lzw\"})\n",
    "    \n",
    "\n",
    "    out_file  = f'../Data/Crop_Classification/S2/{year}/NDVI_M{month}_mean.tif'\n",
    "    \n",
    "    if not path.isfile(out_file):\n",
    "        with rasterio.open(out_file, \"w\", **profile) as dest:\n",
    "            print(out_file)\n",
    "            dest.write(mosaic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a stack of monthly NDVI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_NDVI = glob(f'../Data/Crop_Classification/S2/{year}/NDVI_M*_mean.tif')\n",
    "print(list_NDVI, len(list_NDVI))\n",
    "      \n",
    "with rasterio.open(list_NDVI[0]) as src0:\n",
    "    meta = src0.meta\n",
    "    meta.update(count = len(list_NDVI))\n",
    "        \n",
    "    output = f'../Data/Crop_Classification/S2/{year}/stack_month_NDVI.tif'\n",
    "\n",
    "    if not path.isfile(output):\n",
    "        with rasterio.open(output, 'w', **meta) as dst:\n",
    "            for id, layer in enumerate(list_NDVI, start=1):\n",
    "                    with rasterio.open(layer) as src1:\n",
    "                        dst.write_band(id, src1.read(1))\n",
    "                        meta = src1.meta\n",
    "                        print(id, src1)\n",
    "                    \n",
    "print(output)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate statistics of NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with rasterio.open(f'../Data/Crop_Classification/S2/{year}/stack_month_NDVI.tif') as src:\n",
    "      df_stat_NDVI = pd. DataFrame()\n",
    "      affine = src.transform\n",
    "      output = '../Data/Crop_Classification/Variables/crop_stat_NDVI.geojson'\n",
    "      if not path.isfile(output):\n",
    "            for band in range(1, src.count):\n",
    "                  print(band)\n",
    "                  array = src.read(band)\n",
    "                  df_zonal_stats = pd.DataFrame(zonal_stats(gdf_parcels, array, affine=affine, stats=\"mean median min max count\"))\n",
    "                  df = df_zonal_stats.rename(columns={'mean': f'mean_{band}', 'median': f'median_{band}', 'min': f'min_{band}','max': f'max_{band}','count': f'count_{band}'})\n",
    "                  df_stat_NDVI = pd.concat([df_stat_NDVI, df], axis=1)\n",
    "\n",
    "            gdf_stat_NDVI_parcels = pd.concat([gdf_parcels, df_stat_NDVI], axis=1)\n",
    "            gdf_stat_NDVI_parcels.to_file(output, driver=\"GeoJSON\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reclass the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_stat_NDVI_test = gdf_stat_NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (DHI GRAS)",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e024cb4593cb261d05d85a9dcecfceb536a0f6ff0ecfd5c219e00bdfc750897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
